{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1TWKM5I7aJ4kiHR_iLyaxxNLAF8kEf0cR","authorship_tag":"ABX9TyMV/WEDM9FIPz9CdeK1WSrj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"869ea3626bfc4a19b7411bb5616ce3dd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_10acc795299d40a0a7f5fc928d9a5ece","IPY_MODEL_2d1a7c7274554c88a037c848e32ca1db","IPY_MODEL_c1f5c011e1a845469b82aef0cd72e42b"],"layout":"IPY_MODEL_c948f8f8fd1d4dbbb1dd0ee7f793af6f"}},"10acc795299d40a0a7f5fc928d9a5ece":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_751669e24c5e41ae81313f8c82ab9501","placeholder":"​","style":"IPY_MODEL_9465308d9f8945c58c015fafce8a7538","value":"Map (num_proc=8): 100%"}},"2d1a7c7274554c88a037c848e32ca1db":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_79e4017c999b4addaaccec375a208e1c","max":2341,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2520f2280a404ace9466edc0baa0801a","value":2341}},"c1f5c011e1a845469b82aef0cd72e42b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_72ae4f65315743eb8710d79600062355","placeholder":"​","style":"IPY_MODEL_a27dbfaee83f41dd8587e03282e4856c","value":" 2341/2341 [00:08&lt;00:00, 623.77 examples/s]"}},"c948f8f8fd1d4dbbb1dd0ee7f793af6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"751669e24c5e41ae81313f8c82ab9501":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9465308d9f8945c58c015fafce8a7538":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"79e4017c999b4addaaccec375a208e1c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2520f2280a404ace9466edc0baa0801a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"72ae4f65315743eb8710d79600062355":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a27dbfaee83f41dd8587e03282e4856c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dcda21d19a01482cb42aa558280b5034":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8236fd0e44804fa2934e8349f30dacdf","IPY_MODEL_65e6bcec65934c6db482250c88ac9798","IPY_MODEL_87ca367fe2744d79b28f09c7cd2342f6"],"layout":"IPY_MODEL_ee4f641c601548f6ae3cd3e88f149b32"}},"8236fd0e44804fa2934e8349f30dacdf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed431fa0fa5a4f1194585a2a8c48c994","placeholder":"​","style":"IPY_MODEL_f18f6776c4a147a693a1a8f66e5576b3","value":"tokenizer_config.json: 100%"}},"65e6bcec65934c6db482250c88ac9798":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_80121b73210240bc8984fac343dab7ca","max":2197,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fd5928da8b6c4ce693a6fc12d4a2cbf2","value":2197}},"87ca367fe2744d79b28f09c7cd2342f6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fafba03378ae40d79e0b349254f1da2e","placeholder":"​","style":"IPY_MODEL_dcba127a91fd42968c84b14968cf0656","value":" 2.20k/2.20k [00:00&lt;00:00, 129kB/s]"}},"ee4f641c601548f6ae3cd3e88f149b32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed431fa0fa5a4f1194585a2a8c48c994":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f18f6776c4a147a693a1a8f66e5576b3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"80121b73210240bc8984fac343dab7ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd5928da8b6c4ce693a6fc12d4a2cbf2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fafba03378ae40d79e0b349254f1da2e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dcba127a91fd42968c84b14968cf0656":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1109d20652a44eaf80924b3b94208353":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_95cf638e256e4ef48d7d653f4116402e","IPY_MODEL_b5b1f6b08d334e26ad95856286b2f07a","IPY_MODEL_9c5b90adc4594ee984d29672376c2604"],"layout":"IPY_MODEL_619d2dba8cdf4bbf9399c388b4d21584"}},"95cf638e256e4ef48d7d653f4116402e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7a8c9c1c94d4d5a854f9d5dfe9f2335","placeholder":"​","style":"IPY_MODEL_6b8ea34bf1fd434fad87ec62da3c9acc","value":"spiece.model: 100%"}},"b5b1f6b08d334e26ad95856286b2f07a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_461f06fcb8d54473bfb0f1b6cd64d8e2","max":820370,"min":0,"orientation":"horizontal","style":"IPY_MODEL_93c7e01c04d84f47bcaa2f9b37021123","value":820370}},"9c5b90adc4594ee984d29672376c2604":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_81e3ae912b374a1195c8a115afbe790b","placeholder":"​","style":"IPY_MODEL_36942f2896dc4fc7a00d9d3e42308c86","value":" 820k/820k [00:00&lt;00:00, 4.38MB/s]"}},"619d2dba8cdf4bbf9399c388b4d21584":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7a8c9c1c94d4d5a854f9d5dfe9f2335":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b8ea34bf1fd434fad87ec62da3c9acc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"461f06fcb8d54473bfb0f1b6cd64d8e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93c7e01c04d84f47bcaa2f9b37021123":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"81e3ae912b374a1195c8a115afbe790b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36942f2896dc4fc7a00d9d3e42308c86":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3daa34fa276b40399734caf8d4deccc1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4067e0c2f45d48d6a07e63340f505d58","IPY_MODEL_d3ae7079ec3a49299033708c3ed230ea","IPY_MODEL_330de9a4490f4913941e7d1af4f592a4"],"layout":"IPY_MODEL_e812c0cfc5a4415c9c067e1d011fbb3c"}},"4067e0c2f45d48d6a07e63340f505d58":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b4ef6e4775f41ba896279e91e37d39d","placeholder":"​","style":"IPY_MODEL_767df98fc7c046e4aa0d75f3d3c0a57c","value":"tokenizer.json: 100%"}},"d3ae7079ec3a49299033708c3ed230ea":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5cdcfa89872241718a1f16a9ec9ffdca","max":2399296,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c2f8dc416c18417da25444b147f65fb0","value":2399296}},"330de9a4490f4913941e7d1af4f592a4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_76568fe0c5cc4422b60010a990527bfd","placeholder":"​","style":"IPY_MODEL_17b060c1a2504de5a14d2f06ddbd1c0f","value":" 2.40M/2.40M [00:00&lt;00:00, 7.56MB/s]"}},"e812c0cfc5a4415c9c067e1d011fbb3c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b4ef6e4775f41ba896279e91e37d39d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"767df98fc7c046e4aa0d75f3d3c0a57c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5cdcfa89872241718a1f16a9ec9ffdca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2f8dc416c18417da25444b147f65fb0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"76568fe0c5cc4422b60010a990527bfd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17b060c1a2504de5a14d2f06ddbd1c0f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1ede45473d4c44a99b25f1d3de4b50be":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f6ba1516ddc74eb79c59466c8d1cc03b","IPY_MODEL_506ea1fbe7b440c3a182933a8145bae7","IPY_MODEL_d5de66ace7ff459492306fbbff994bf5"],"layout":"IPY_MODEL_ffcf07c67962452bb43a626405f7f3ad"}},"f6ba1516ddc74eb79c59466c8d1cc03b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5af8ed125ac64cd18e10fa8bb7202f98","placeholder":"​","style":"IPY_MODEL_6d29b7b6b9714e9c96d20bc4ba0f85b9","value":"special_tokens_map.json: 100%"}},"506ea1fbe7b440c3a182933a8145bae7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e18a9b2bccb4184914d5382e82fe46d","max":2117,"min":0,"orientation":"horizontal","style":"IPY_MODEL_79002afcd6224b3ba408e9874095a873","value":2117}},"d5de66ace7ff459492306fbbff994bf5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9fa6fa3b4c0e4ba5864221c3db8f2612","placeholder":"​","style":"IPY_MODEL_4cfc19bcb82244a7a9137ca83dd22101","value":" 2.12k/2.12k [00:00&lt;00:00, 61.6kB/s]"}},"ffcf07c67962452bb43a626405f7f3ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5af8ed125ac64cd18e10fa8bb7202f98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d29b7b6b9714e9c96d20bc4ba0f85b9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1e18a9b2bccb4184914d5382e82fe46d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79002afcd6224b3ba408e9874095a873":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9fa6fa3b4c0e4ba5864221c3db8f2612":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4cfc19bcb82244a7a9137ca83dd22101":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2716271002a54f0a8594b197cebd6d10":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_34607c23d33c444eaaed20d0aa7fc984","IPY_MODEL_78a17c708a5e47a2bbbf91844dbc4f3e","IPY_MODEL_90af7882a3fc40659c4992ce07736b22"],"layout":"IPY_MODEL_842d61a466484facbb7a653ba6e1d98e"}},"34607c23d33c444eaaed20d0aa7fc984":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b22c75873c9245b8abda12d66e95ae76","placeholder":"​","style":"IPY_MODEL_8fe2bcf981a745b1a9463ad6d0defff4","value":"Downloading builder script: "}},"78a17c708a5e47a2bbbf91844dbc4f3e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d4562b052be4c26aacabff1187d244e","max":2169,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9c56ad3c6362405091e3238c66f9c109","value":2169}},"90af7882a3fc40659c4992ce07736b22":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b55fc9684c5849c28d4444d7a9a5a31d","placeholder":"​","style":"IPY_MODEL_a0e9d80861ef44888b94746f3fbd49cf","value":" 5.65k/? [00:00&lt;00:00, 325kB/s]"}},"842d61a466484facbb7a653ba6e1d98e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b22c75873c9245b8abda12d66e95ae76":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8fe2bcf981a745b1a9463ad6d0defff4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1d4562b052be4c26aacabff1187d244e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c56ad3c6362405091e3238c66f9c109":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b55fc9684c5849c28d4444d7a9a5a31d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0e9d80861ef44888b94746f3fbd49cf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2626b38b488f4b2f8bee3397e5efdd4c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_876d54c125b640f793aa66a2d4767bfd","IPY_MODEL_7f71c5127fc54655ab8a41ed9803c3dd","IPY_MODEL_18f025843b0044649817b941233f87d8"],"layout":"IPY_MODEL_0060fbafcc314eba8b56ad0e063f5574"}},"876d54c125b640f793aa66a2d4767bfd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2668f917b71451b96d7681f23c8cd23","placeholder":"​","style":"IPY_MODEL_0698e0dc37f541d9b42c05a6c2ea4fe5","value":"Map (num_proc=10): 100%"}},"7f71c5127fc54655ab8a41ed9803c3dd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_62ae7d89df534112b0ac15748a5311a3","max":586,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9cd51d4187c7452e956cfe97f059c0cf","value":586}},"18f025843b0044649817b941233f87d8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b61978cd4824e5ea472992e1428cd97","placeholder":"​","style":"IPY_MODEL_a516742bf4aa4c50aa77b3247a9eb89c","value":" 586/586 [00:02&lt;00:00, 404.37 examples/s]"}},"0060fbafcc314eba8b56ad0e063f5574":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2668f917b71451b96d7681f23c8cd23":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0698e0dc37f541d9b42c05a6c2ea4fe5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"62ae7d89df534112b0ac15748a5311a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9cd51d4187c7452e956cfe97f059c0cf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7b61978cd4824e5ea472992e1428cd97":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a516742bf4aa4c50aa77b3247a9eb89c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f80dda9398e644429c6f4e65a8ce4e51":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_07bea5a146104d02bf27c7d7cfcaa91a","IPY_MODEL_c18e244f59d34472a1d0391dd43639c7","IPY_MODEL_80af7b2f820d407cb467ff3c1b4a2de0"],"layout":"IPY_MODEL_8227031d1db74431873511fdaa72b063"}},"07bea5a146104d02bf27c7d7cfcaa91a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_39647e5aada047f1be6ff669968869cc","placeholder":"​","style":"IPY_MODEL_97da54a5d3384a72b9c02988ca1c8458","value":"100%"}},"c18e244f59d34472a1d0391dd43639c7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8116476fa0c94615a7713d114115c85f","max":19,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7a55f8f901424eefa33c430bd31929ea","value":19}},"80af7b2f820d407cb467ff3c1b4a2de0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7b5f3c475964857b81f177f6814f8e6","placeholder":"​","style":"IPY_MODEL_c143774406004dce9895e7820e4c1275","value":" 19/19 [01:58&lt;00:00,  5.26s/it]"}},"8227031d1db74431873511fdaa72b063":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39647e5aada047f1be6ff669968869cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97da54a5d3384a72b9c02988ca1c8458":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8116476fa0c94615a7713d114115c85f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a55f8f901424eefa33c430bd31929ea":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b7b5f3c475964857b81f177f6814f8e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c143774406004dce9895e7820e4c1275":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"8aZmxFZTsniv"},"outputs":[],"source":["%%capture\n","!pip install datasets evaluate transformers[sentencepiece]\n","!pip install rouge_score"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sJBt_RWEg4Qy","executionInfo":{"status":"ok","timestamp":1716732247868,"user_tz":-420,"elapsed":13199,"user":{"displayName":"Kiệt Ngô","userId":"10546302795973663225"}},"outputId":"18b32e43-79e9-4988-cbab-a049511a230a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!gsutil cp -r gs://vietai_public/viT5/data/vietnews .\n","!gsutil cp -r gs://vietai_public/viT5/data/wikilingua ."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QheceW6HvG58","executionInfo":{"status":"ok","timestamp":1716474400763,"user_tz":-420,"elapsed":15577,"user":{"displayName":"Kiệt Ngô","userId":"10546302795973663225"}},"outputId":"89ccb74f-91bc-463a-895e-4f5f2c849eca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Caught CTRL-C (signal 2) - exiting\n","^C\n","Copying gs://vietai_public/viT5/data/wikilingua/test.tsv...\n","Copying gs://vietai_public/viT5/data/wikilingua/train.tsv...\n","Caught CTRL-C (signal 2) - exiting\n","^C\n"]}]},{"cell_type":"code","source":["from datasets import Dataset\n","from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainer, TrainingArguments, Seq2SeqTrainingArguments\n","from tqdm.notebook import tqdm\n","from torch.utils.data import DataLoader\n","import json\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import pickle\n","import pandas as pd\n","import csv"],"metadata":{"id":"Uu9oCbyvvI19"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def save_pklFile(input_file, name):\n","  with open(f'/content/drive/MyDrive/ChatBot/data/{name}.pkl', 'wb') as f:\n","\n","    # A new file will be created\n","    pickle.dump(input_file, f)"],"metadata":{"id":"NthS5QP7tX7X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def process_dataset(path):\n","  with open(path, 'r', encoding='utf-8') as df:\n","    df = json.load(df)\n","  train, test = train_test_split([x for x in df.keys()], test_size=0.2, random_state = 42)\n","  train = [df[x] for x in train]\n","  X_train = [x['document'] for x in train]\n","  y_train = [x['summary'] for x in train]\n","  save_pklFile(train, 'train')\n","\n","  test = [df[x] for x in test]\n","  X_test = [x['document'] for x in test]\n","  y_test = [x['summary'] for x in test]\n","  save_pklFile(test, 'test')\n","  return X_train, X_test, y_train, y_test"],"metadata":{"id":"vRQrchl6KqQP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_pklFile(path):\n","  with open(path, 'rb') as f:\n","\n","    # Call load method to deserialze\n","    return pickle.load(f, encoding='utf-8')"],"metadata":{"id":"4UKkN6k0uVzH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_dataset():\n","  train = load_pklFile('/content/drive/MyDrive/ChatBot/data/train.pkl')\n","  X_train = [x['document'] for x in train]\n","  y_train = [x['summary'] for x in train]\n","\n","\n","  test = load_pklFile('/content/drive/MyDrive/ChatBot/data/test.pkl')\n","  X_test = [x['document'] for x in test]\n","  y_test = [x['summary'] for x in test]\n","  return X_train, X_test, y_train, y_test"],"metadata":{"id":"8YNlwW9sumhQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# X_train, X_test, y_train, y_test = process_dataset('/content/drive/MyDrive/ChatBot/data/data_DT_news.json')\n","X_train, X_test, y_train, y_test = load_dataset()"],"metadata":{"id":"9UIEp-deLA75"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(\"VietAI/vit5-base\")\n","# model = AutoModelForSeq2SeqLM.from_pretrained(\"VietAI/vit5-base\")\n","# model.to('cuda')\n","\n","model = AutoModelForSeq2SeqLM.from_pretrained(\"/content/drive/MyDrive/ChatBot/tmp_1/checkpoint-7618\")\n","model.to('cuda')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":2629,"referenced_widgets":["dcda21d19a01482cb42aa558280b5034","8236fd0e44804fa2934e8349f30dacdf","65e6bcec65934c6db482250c88ac9798","87ca367fe2744d79b28f09c7cd2342f6","ee4f641c601548f6ae3cd3e88f149b32","ed431fa0fa5a4f1194585a2a8c48c994","f18f6776c4a147a693a1a8f66e5576b3","80121b73210240bc8984fac343dab7ca","fd5928da8b6c4ce693a6fc12d4a2cbf2","fafba03378ae40d79e0b349254f1da2e","dcba127a91fd42968c84b14968cf0656","1109d20652a44eaf80924b3b94208353","95cf638e256e4ef48d7d653f4116402e","b5b1f6b08d334e26ad95856286b2f07a","9c5b90adc4594ee984d29672376c2604","619d2dba8cdf4bbf9399c388b4d21584","d7a8c9c1c94d4d5a854f9d5dfe9f2335","6b8ea34bf1fd434fad87ec62da3c9acc","461f06fcb8d54473bfb0f1b6cd64d8e2","93c7e01c04d84f47bcaa2f9b37021123","81e3ae912b374a1195c8a115afbe790b","36942f2896dc4fc7a00d9d3e42308c86","3daa34fa276b40399734caf8d4deccc1","4067e0c2f45d48d6a07e63340f505d58","d3ae7079ec3a49299033708c3ed230ea","330de9a4490f4913941e7d1af4f592a4","e812c0cfc5a4415c9c067e1d011fbb3c","1b4ef6e4775f41ba896279e91e37d39d","767df98fc7c046e4aa0d75f3d3c0a57c","5cdcfa89872241718a1f16a9ec9ffdca","c2f8dc416c18417da25444b147f65fb0","76568fe0c5cc4422b60010a990527bfd","17b060c1a2504de5a14d2f06ddbd1c0f","1ede45473d4c44a99b25f1d3de4b50be","f6ba1516ddc74eb79c59466c8d1cc03b","506ea1fbe7b440c3a182933a8145bae7","d5de66ace7ff459492306fbbff994bf5","ffcf07c67962452bb43a626405f7f3ad","5af8ed125ac64cd18e10fa8bb7202f98","6d29b7b6b9714e9c96d20bc4ba0f85b9","1e18a9b2bccb4184914d5382e82fe46d","79002afcd6224b3ba408e9874095a873","9fa6fa3b4c0e4ba5864221c3db8f2612","4cfc19bcb82244a7a9137ca83dd22101"]},"id":"LVBcYQ8OvKe9","executionInfo":{"status":"ok","timestamp":1716733087514,"user_tz":-420,"elapsed":14408,"user":{"displayName":"Kiệt Ngô","userId":"10546302795973663225"}},"outputId":"21e9c634-970d-4aab-a5b8-4eb377920aae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dcda21d19a01482cb42aa558280b5034"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["spiece.model:   0%|          | 0.00/820k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1109d20652a44eaf80924b3b94208353"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/2.40M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3daa34fa276b40399734caf8d4deccc1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/2.12k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ede45473d4c44a99b25f1d3de4b50be"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["T5ForConditionalGeneration(\n","  (shared): Embedding(36096, 768)\n","  (encoder): T5Stack(\n","    (embed_tokens): Embedding(36096, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-11): 11 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): T5Stack(\n","    (embed_tokens): Embedding(36096, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-11): 11 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=36096, bias=False)\n",")"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["def preprocess_function(examples):\n","    model_inputs = tokenizer(\n","        examples[\"inputs\"], max_length=1024, truncation=True, padding=True\n","    )\n","\n","    with tokenizer.as_target_tokenizer():\n","        labels = tokenizer(\n","            examples[\"labels\"], max_length=256, truncation=True, padding=True\n","        )\n","    model_inputs['labels'] = labels['input_ids']\n","    model_inputs['input_ids'] = model_inputs['input_ids']\n","    return model_inputs"],"metadata":{"id":"uzVzar0MvMJh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_lines = []\n","label_lines = []\n","\n","# task = 'wikilingua'\n","# train_file = 'train.tsv'\n","\n","# with open(f'{task}/{train_file}') as file:\n","#   for line in file:\n","#     line = line.strip().split('\\t')\n","#     input_lines.append(line[0] +'')\n","#     label_lines.append(line[1])\n","\n","\n","\n","\n","dict_obj = {'inputs': X_train, 'labels': y_train}\n","dataset = Dataset.from_dict(dict_obj)\n","tokenized_datasets = dataset.map(preprocess_function, batched=True, remove_columns=['inputs'], num_proc=8)\n"],"metadata":{"id":"395JfWXpwICo","colab":{"base_uri":"https://localhost:8080/","height":416,"referenced_widgets":["869ea3626bfc4a19b7411bb5616ce3dd","10acc795299d40a0a7f5fc928d9a5ece","2d1a7c7274554c88a037c848e32ca1db","c1f5c011e1a845469b82aef0cd72e42b","c948f8f8fd1d4dbbb1dd0ee7f793af6f","751669e24c5e41ae81313f8c82ab9501","9465308d9f8945c58c015fafce8a7538","79e4017c999b4addaaccec375a208e1c","2520f2280a404ace9466edc0baa0801a","72ae4f65315743eb8710d79600062355","a27dbfaee83f41dd8587e03282e4856c"]},"executionInfo":{"status":"ok","timestamp":1716478125940,"user_tz":-420,"elapsed":9200,"user":{"displayName":"Kiệt Ngô","userId":"10546302795973663225"}},"outputId":"a0080fbd-3ab3-408e-bafe-e65919e27945"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"output_type":"display_data","data":{"text/plain":["Map (num_proc=8):   0%|          | 0/2341 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"869ea3626bfc4a19b7411bb5616ce3dd"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3946: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3946: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3946: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3946: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3946: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3946: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3946: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3946: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["!pip install accelerate==0.27.2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G7gAL_iNNTT4","executionInfo":{"status":"ok","timestamp":1716732369251,"user_tz":-420,"elapsed":79179,"user":{"displayName":"Kiệt Ngô","userId":"10546302795973663225"}},"outputId":"ee6860d0-6133-4e1d-cc14-736fd50f51f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting accelerate==0.27.2\n","  Downloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.27.2) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.27.2) (24.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.27.2) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.27.2) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.27.2) (2.3.0+cu121)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate==0.27.2) (0.23.1)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.27.2) (0.4.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate==0.27.2)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate==0.27.2)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate==0.27.2)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate==0.27.2)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate==0.27.2)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate==0.27.2)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate==0.27.2)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate==0.27.2)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate==0.27.2)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.10.0->accelerate==0.27.2)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate==0.27.2)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.27.2)\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate==0.27.2) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate==0.27.2) (4.66.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.27.2) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.27.2) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.27.2) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.27.2) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.27.2) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.27.2) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n","Successfully installed accelerate-0.27.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"]}]},{"cell_type":"code","source":["data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"pt\")\n","\n","\n","training_args = Seq2SeqTrainingArguments(\"/content/drive/MyDrive/ChatBot/tmp_1/\",\n","                                      do_train=True,\n","                                      do_eval=False,\n","                                      num_train_epochs=20,\n","                                      learning_rate=1e-5,\n","                                      warmup_ratio=0.05,\n","                                      weight_decay=0.01,\n","                                      per_device_train_batch_size=4,\n","                                      per_device_eval_batch_size=4,\n","                                      logging_dir='/content/drive/MyDrive/ChatBot/tmp_1/log',\n","                                      group_by_length=True,\n","                                      save_strategy=\"epoch\",\n","                                      save_total_limit=3,\n","                                      #eval_steps=1,\n","                                      #evaluation_strategy=\"steps\",\n","                                      # evaluation_strategy=\"no\",\n","                                      fp16=True,\n","                                      )\n","\n","\n","\n","# AdaFactor for ViT5-large models as it based on T5v1.1.\n","# See https://medium.com/the-artificial-impostor/paper-adafactor-adaptive-learning-rates-with-sublinear-memory-cost-a543abffa37\n","#\n","from transformers.optimization import Adafactor, AdafactorSchedule\n","optimizer = Adafactor(\n","    model.parameters(),\n","    lr=1e-3,\n","    eps=(1e-30, 1e-3),\n","    clip_threshold=1.0,\n","    decay_rate=-0.8,\n","    beta1=None,\n","    weight_decay=0.0,\n","    relative_step=False,\n","    scale_parameter=False,\n","    warmup_init=False\n",")\n","\n","lr_scheduler = AdafactorSchedule(optimizer)"],"metadata":{"id":"KaluUpYlwL62"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_datasets,\n","    data_collator=data_collator,\n",")\n","\n","trainer.train()"],"metadata":{"id":"J2Upw8ldwOdN","colab":{"base_uri":"https://localhost:8080/","height":554},"outputId":"0f263af9-48d3-4661-ff59-5d91eb2c74fc","executionInfo":{"status":"error","timestamp":1716478050639,"user_tz":-420,"elapsed":2280647,"user":{"displayName":"Kiệt Ngô","userId":"10546302795973663225"}}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2752' max='11720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 2752/11720 37:52 < 2:03:30, 1.21 it/s, Epoch 4.69/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.274600</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.243000</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.232100</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.223900</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.211100</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-2cbf8aef9f9d>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1883\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1884\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1885\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1886\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1887\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2219\u001b[0m                     \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2220\u001b[0m                     \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_torch_xla_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2221\u001b[0;31m                     \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2222\u001b[0m                 ):\n\u001b[1;32m   2223\u001b[0m                     \u001b[0;31m# if loss is nan or inf simply add the average of previous logged losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_datasets,\n","    data_collator=data_collator,\n",")\n","\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":961},"id":"uKpyk_5Nif9Y","executionInfo":{"status":"error","timestamp":1715872981028,"user_tz":-420,"elapsed":7721306,"user":{"displayName":"Kiệt Ngô","userId":"10546302795973663225"}},"outputId":"d8b2f254-e805-49ca-f50e-bb88dcc40d3b"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='9501' max='11720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 9501/11720 2:08:31 < 30:01, 1.23 it/s, Epoch 16.21/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.279200</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.252300</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.230700</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.209500</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.185000</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.169100</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.152800</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.134600</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>0.124900</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.119200</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>0.111100</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>0.105000</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>0.097800</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>0.094800</td>\n","    </tr>\n","    <tr>\n","      <td>7500</td>\n","      <td>0.090600</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>0.088800</td>\n","    </tr>\n","    <tr>\n","      <td>8500</td>\n","      <td>0.085400</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>0.084700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"error","ename":"FailedPreconditionError","evalue":"/content/drive/MyDrive/ChatBot/tmp_1/log/events.out.tfevents.1715865265.d6c5bc60f404.2784.0; Transport endpoint is not connected","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-2cbf8aef9f9d>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1857\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1858\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1859\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1860\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1861\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2276\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2278\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2279\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2280\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_substep_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2656\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore_flos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2658\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mlog\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   3056\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"step\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3057\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3058\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3060\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer_callback.py\u001b[0m in \u001b[0;36mon_log\u001b[0;34m(self, args, state, control, logs)\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainerState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainerControl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_log\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_prediction_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainerState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainerControl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer_callback.py\u001b[0m in \u001b[0;36mcall_event\u001b[0;34m(self, event, args, state, control, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             result = getattr(callback, event)(\n\u001b[0m\u001b[1;32m    416\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m                 \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/integrations/integration_utils.py\u001b[0m in \u001b[0;36mon_log\u001b[0;34m(self, args, state, control, logs, **kwargs)\u001b[0m\n\u001b[1;32m    656\u001b[0m                         \u001b[0;34m\"is incorrect so we dropped this attribute.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m                     )\n\u001b[0;32m--> 658\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/writer.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1254\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mwriter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_writers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1256\u001b[0;31m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/writer.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mdisk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \"\"\"\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorboard/summary/writer/event_file_writer.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mwritten\u001b[0m \u001b[0mto\u001b[0m \u001b[0mdisk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \"\"\"\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_async_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorboard/summary/writer/event_file_writer.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Writer is closed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_byte_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m             \u001b[0;31m# Check the status again in case the background worker thread has\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;31m# failed in the meantime to avoid waiting until the next call to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorboard/summary/writer/record_writer.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \"\"\"\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_writable_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_writable_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFailedPreconditionError\u001b[0m: /content/drive/MyDrive/ChatBot/tmp_1/log/events.out.tfevents.1715865265.d6c5bc60f404.2784.0; Transport endpoint is not connected"]}]},{"cell_type":"code","source":["trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_datasets,\n","    data_collator=data_collator,\n",")\n","\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"IOYf-mAqEXmk","executionInfo":{"status":"error","timestamp":1716484604628,"user_tz":-420,"elapsed":1460001,"user":{"displayName":"Kiệt Ngô","userId":"10546302795973663225"}},"outputId":"6a5955ce-63bd-49aa-f4d9-5ef0e4b79195"},"execution_count":null,"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='5972' max='11720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 5972/11720 1:23:25 < 1:20:19, 1.19 it/s, Epoch 10.19/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.279200</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.252300</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.230700</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.209500</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.185000</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.169100</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.152800</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.134600</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>0.124900</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.119200</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>0.111100</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='7709' max='11720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 7709/11720 1:47:46 < 56:05, 1.19 it/s, Epoch 13.15/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.279200</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.252300</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.230700</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.209500</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.185000</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.169100</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.152800</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.134600</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>0.124900</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.119200</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>0.111100</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>0.105000</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>0.097800</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>0.094800</td>\n","    </tr>\n","    <tr>\n","      <td>7500</td>\n","      <td>0.090600</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-2cbf8aef9f9d>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1883\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1884\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1885\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1886\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1887\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2177\u001b[0m             \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2178\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2179\u001b[0m                 \u001b[0mtotal_batched_samples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/data_loader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    459\u001b[0m                 \u001b[0;31m# But we still move it to the device so it is done before `StopIteration` is reached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m                     \u001b[0mcurrent_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msend_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m                 \u001b[0mnext_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_batches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mskip_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         return type(tensor)(\n\u001b[0;32m--> 167\u001b[0;31m             {\n\u001b[0m\u001b[1;32m    168\u001b[0m                 \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskip_keys\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msend_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    166\u001b[0m         return type(tensor)(\n\u001b[1;32m    167\u001b[0m             {\n\u001b[0;32m--> 168\u001b[0;31m                 \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskip_keys\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msend_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             }\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xpu:0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# .to() doesn't accept non_blocking as kwarg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_datasets,\n","    data_collator=data_collator,\n",")\n","\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":397},"id":"HEmTq_PWJ1LB","executionInfo":{"status":"error","timestamp":1715875784101,"user_tz":-420,"elapsed":168837,"user":{"displayName":"Kiệt Ngô","userId":"10546302795973663225"}},"outputId":"bd1ce580-a68d-4971-832d-dc3fff1fefb1"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='209' max='11720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [  209/11720 02:42 < 2:30:36, 1.27 it/s, Epoch 0.35/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-2cbf8aef9f9d>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1857\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1858\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1859\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1860\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1861\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2202\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2203\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2205\u001b[0m                 if (\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3137\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3138\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3159\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3160\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3161\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3162\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3163\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 817\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m     \u001b[0;31m# To act like a decorator so that it can be popped when doing `extract_model_from_parallel`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_fp32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py\u001b[0m in \u001b[0;36mdecorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautocast_instance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__script_unsupported\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"@autocast() decorator is not supported in script mode\"\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m         \u001b[0;31m# Decode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1742\u001b[0;31m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[1;32m   1743\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1744\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1107\u001b[0m                 )\n\u001b[1;32m   1108\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1109\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m   1110\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    717\u001b[0m                 \u001b[0mquery_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m             cross_attention_outputs = self.layer[1](\n\u001b[0m\u001b[1;32m    720\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m                 \u001b[0mkey_value_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, key_value_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, query_length, output_attentions)\u001b[0m\n\u001b[1;32m    628\u001b[0m     ):\n\u001b[1;32m    629\u001b[0m         \u001b[0mnormed_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m         attention_output = self.EncDecAttention(\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mnormed_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;31m# compute scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         scores = torch.matmul(\n\u001b[0m\u001b[1;32m    527\u001b[0m             \u001b[0mquery_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         )  # equivalent of torch.einsum(\"bnqd,bnkd->bnqk\", query_states, key_states), compatible with onnx op>9\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["from datasets import load_metric\n","metric = load_metric(\"rouge\")"],"metadata":{"id":"1H9P09ZWwR9s","executionInfo":{"status":"ok","timestamp":1716733103685,"user_tz":-420,"elapsed":1213,"user":{"displayName":"Kiệt Ngô","userId":"10546302795973663225"}},"colab":{"base_uri":"https://localhost:8080/","height":173,"referenced_widgets":["2716271002a54f0a8594b197cebd6d10","34607c23d33c444eaaed20d0aa7fc984","78a17c708a5e47a2bbbf91844dbc4f3e","90af7882a3fc40659c4992ce07736b22","842d61a466484facbb7a653ba6e1d98e","b22c75873c9245b8abda12d66e95ae76","8fe2bcf981a745b1a9463ad6d0defff4","1d4562b052be4c26aacabff1187d244e","9c56ad3c6362405091e3238c66f9c109","b55fc9684c5849c28d4444d7a9a5a31d","a0e9d80861ef44888b94746f3fbd49cf"]},"outputId":"7fff6cfc-2cef-4ad9-8906-334353e7c86c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-6-ffe5587f2e49>:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n","  metric = load_metric(\"rouge\")\n","/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/rouge/rouge.py\n","You can avoid this message in future by passing the argument `trust_remote_code=True`.\n","Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/2.17k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2716271002a54f0a8594b197cebd6d10"}},"metadata":{}}]},{"cell_type":"code","source":["input_lines = []\n","label_lines = []\n","# with open(f'{task}/test.tsv') as file:\n","#   for line in file:\n","#     line = line.strip().split('\\t')\n","#     input = line[0]\n","#     input_lines.append(input +'')\n","#     label_lines.append(line[1])\n","\n","\n","\n","input_lines  = X_test\n","label_lines = y_test\n","dict_obj = {'inputs': input_lines, 'labels': label_lines}\n","\n","dataset = Dataset.from_dict(dict_obj)\n","test_tokenized_datasets = dataset.map(preprocess_function, batched=True, remove_columns=['inputs'], num_proc=10)\n","data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"pt\")"],"metadata":{"id":"VJoMSWDrwTmC","executionInfo":{"status":"ok","timestamp":1716739516125,"user_tz":-420,"elapsed":3520,"user":{"displayName":"Kiệt Ngô","userId":"10546302795973663225"}},"colab":{"base_uri":"https://localhost:8080/","height":451,"referenced_widgets":["2626b38b488f4b2f8bee3397e5efdd4c","876d54c125b640f793aa66a2d4767bfd","7f71c5127fc54655ab8a41ed9803c3dd","18f025843b0044649817b941233f87d8","0060fbafcc314eba8b56ad0e063f5574","d2668f917b71451b96d7681f23c8cd23","0698e0dc37f541d9b42c05a6c2ea4fe5","62ae7d89df534112b0ac15748a5311a3","9cd51d4187c7452e956cfe97f059c0cf","7b61978cd4824e5ea472992e1428cd97","a516742bf4aa4c50aa77b3247a9eb89c"]},"outputId":"d0af3080-7e7f-4a03-8ec1-c8665ba51bc7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"output_type":"display_data","data":{"text/plain":["Map (num_proc=10):   0%|          | 0/586 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2626b38b488f4b2f8bee3397e5efdd4c"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3946: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3946: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3946: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3946: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3946: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3946: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3946: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3946: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3946: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3946: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","source":["# Inference"],"metadata":{"id":"I16IwdzooLId"}},{"cell_type":"code","source":["model = AutoModelForSeq2SeqLM.from_pretrained(\"/content/drive/MyDrive/ChatBot/tmp_1/checkpoint-7618\")\n","model.to('cuda')"],"metadata":{"id":"YLhAUDj9wVTm","executionInfo":{"status":"ok","timestamp":1716733184856,"user_tz":-420,"elapsed":4165,"user":{"displayName":"Kiệt Ngô","userId":"10546302795973663225"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e2b7a722-3e5b-4f1a-97a4-05f673fe82ae"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["T5ForConditionalGeneration(\n","  (shared): Embedding(36096, 768)\n","  (encoder): T5Stack(\n","    (embed_tokens): Embedding(36096, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-11): 11 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): T5Stack(\n","    (embed_tokens): Embedding(36096, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-11): 11 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=36096, bias=False)\n",")"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","metrics = load_metric('rouge')\n","\n","max_target_length = 256\n","dataloader = torch.utils.data.DataLoader(test_tokenized_datasets, collate_fn=data_collator, batch_size=32)\n","\n","predictions = []\n","references = []\n","for i, batch in enumerate(tqdm(dataloader)):\n","  outputs = model.generate(\n","      input_ids=batch['input_ids'].to('cuda'),\n","      max_length=max_target_length,\n","      attention_mask=batch['attention_mask'].to('cuda'),\n","  )\n","  with tokenizer.as_target_tokenizer():\n","    outputs = [tokenizer.decode(out, clean_up_tokenization_spaces=False, skip_special_tokens=True) for out in outputs]\n","\n","    labels = np.where(batch['labels'] != -100,  batch['labels'], tokenizer.pad_token_id)\n","    actuals = [tokenizer.decode(out, clean_up_tokenization_spaces=False, skip_special_tokens=True) for out in labels]\n","  predictions.extend(outputs)\n","  references.extend(actuals)\n","  metrics.add_batch(predictions=outputs, references=actuals)\n","\n","\n","metrics.compute()"],"metadata":{"id":"FK0WJoq_wXWt","executionInfo":{"status":"ok","timestamp":1716739643439,"user_tz":-420,"elapsed":122245,"user":{"displayName":"Kiệt Ngô","userId":"10546302795973663225"}},"colab":{"base_uri":"https://localhost:8080/","height":381,"referenced_widgets":["f80dda9398e644429c6f4e65a8ce4e51","07bea5a146104d02bf27c7d7cfcaa91a","c18e244f59d34472a1d0391dd43639c7","80af7b2f820d407cb467ff3c1b4a2de0","8227031d1db74431873511fdaa72b063","39647e5aada047f1be6ff669968869cc","97da54a5d3384a72b9c02988ca1c8458","8116476fa0c94615a7713d114115c85f","7a55f8f901424eefa33c430bd31929ea","b7b5f3c475964857b81f177f6814f8e6","c143774406004dce9895e7820e4c1275"]},"outputId":"c44f11c6-67f1-4cfc-d9bb-bace16671981"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/rouge/rouge.py\n","You can avoid this message in future by passing the argument `trust_remote_code=True`.\n","Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/19 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f80dda9398e644429c6f4e65a8ce4e51"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3946: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["{'rouge1': AggregateScore(low=Score(precision=0.5994873262947822, recall=0.5661410243981952, fmeasure=0.5722689746501982), mid=Score(precision=0.6083937931178482, recall=0.5764406546118552, fmeasure=0.57976059203447), high=Score(precision=0.6170563041924981, recall=0.5864970823070722, fmeasure=0.5863885959039816)),\n"," 'rouge2': AggregateScore(low=Score(precision=0.2419191711068629, recall=0.22965437133937291, fmeasure=0.2312699535515112), mid=Score(precision=0.25179716372008343, recall=0.23952599600818758, fmeasure=0.24036528873036422), high=Score(precision=0.26165323758595455, recall=0.249274900306397, fmeasure=0.24956464271572648)),\n"," 'rougeL': AggregateScore(low=Score(precision=0.3648138509117503, recall=0.34484721159939574, fmeasure=0.34803925955910386), mid=Score(precision=0.37299367594717403, recall=0.3529670046215674, fmeasure=0.35499203430012305), high=Score(precision=0.3816870842509065, recall=0.36152565881505727, fmeasure=0.36212564522023843)),\n"," 'rougeLsum': AggregateScore(low=Score(precision=0.36456754032429306, recall=0.3450336362198041, fmeasure=0.34779526845430053), mid=Score(precision=0.37360870118135414, recall=0.35331063096203696, fmeasure=0.3553309771274256), high=Score(precision=0.3814555625173809, recall=0.36111122433870524, fmeasure=0.362045979170636))}"]},"metadata":{},"execution_count":213}]},{"cell_type":"code","source":["[{k: v.mid.fmeasure} for k,v in metrics.compute(predictions=predictions, references=references).items()]"],"metadata":{"id":"2gE1dxygwYl6","executionInfo":{"status":"ok","timestamp":1716733352682,"user_tz":-420,"elapsed":4169,"user":{"displayName":"Kiệt Ngô","userId":"10546302795973663225"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"317d624d-87f4-4ddd-afbd-59f959a5af37"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'rouge1': 0.57976059203447},\n"," {'rouge2': 0.24036528873036422},\n"," {'rougeL': 0.35499203430012305},\n"," {'rougeLsum': 0.3553309771274256}]"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"VietAI/vit5-base-vietnews-summarization\")\n","# model = AutoModelForSeq2SeqLM.from_pretrained(\"VietAI/vit5-base-vietnews-summarization\")\n","# model.cuda()\n","\n","sentence = \"VietAI là tổ chức phi lợi nhuận với sứ mệnh ươm mầm tài năng về trí tuệ nhân tạo và xây dựng một cộng đồng các chuyên gia trong lĩnh vực trí tuệ nhân tạo đẳng cấp quốc tế tại Việt Nam.\"\n","sentence = sentence + \"</s>\"\n","encoding = tokenizer(sentence, return_tensors=\"pt\")\n","input_ids, attention_masks = encoding[\"input_ids\"].to(\"cuda\"), encoding[\"attention_mask\"].to(\"cuda\")\n","outputs = model.generate(\n","    input_ids=input_ids, attention_mask=attention_masks,\n","    max_length=256,\n","    early_stopping=True\n",")\n","for output in outputs:\n","    line = tokenizer.decode(output, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n","    print(line)\n"],"metadata":{"id":"_AWO7u3VuFgG","executionInfo":{"status":"ok","timestamp":1715526976649,"user_tz":-420,"elapsed":1423,"user":{"displayName":"Kiệt Ngô","userId":"10546302795973663225"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ab4f4e25-1c75-4456-9eeb-617070e6ea39"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tổ chức phi lợi nhuận VietAI hợp tác với các công ty phần mềm và trí tuệ nhân tạo hàng đầu tại Việt Nam, với mong muốn mang đến cho cộng đồng những chuyên gia, nhà khoa học, nhà khoa học và doanh nghiệp.\n"]}]},{"cell_type":"code","source":["def inference(sentence):\n","  sentence = sentence + \"</s>\"\n","  encoding = tokenizer(sentence, return_tensors=\"pt\")\n","  input_ids, attention_masks = encoding[\"input_ids\"].to(\"cuda\"), encoding[\"attention_mask\"].to(\"cuda\")\n","  outputs = model.generate(\n","      input_ids=input_ids, attention_mask=attention_masks,\n","      max_length=256,\n","      early_stopping=True\n","  )\n","  for output in outputs:\n","      line = tokenizer.decode(output, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n","  return line"],"metadata":{"id":"iUvTy_ZvYI0F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["txt = 'Cán bộ doanh nghiệp nêu thực tế nhiều lao động coi nhẹ tác phong làm việc, đi trễ, về sớm, hoặc đến đúng giờ điểm danh rồi làm việc riêng khiến năng suất không cao.Tại Diễn đàn nâng cao năng suất lao động quốc gia ngày 26/5, ông Mai Thiên Ân, Trưởng phòng sản xuất Công ty TNHH Intel Products Việt Nam, phản ánh thực tế tại nhiều nơi làm việc ở Việt Nam. Một bộ phận lao động không tuân thủ giờ giấc tác phong, có mặt ở cơ quan đúng giờ để điểm danh rồi ăn sáng, uống trà gây đình trệ công việc.Có doanh nghiệp lao động còn lấy sản phẩm bán ra ngoài khiến công ty bị thiệt hại hàng trăm triệu đồng, ảnh hưởng uy tín, mang tiếng văn hóa và con người Việt Nam. Trong sản xuất, một bộ phận lao động không tuân thủ quy trình khiến sản phẩm lỗi làm ảnh hưởng thương hiệu doanh nghiệp, lòng tin đối tác. Thậm chí, lao động không tuân thủ quy định dẫn đến nhiều vụ tai nạn. Ông Ân nhấn mạnh tác phong, kỷ luật làm việc còn bị xem nhẹ trong khi đây là yếu tố giúp tăng thu nhập lao động, nâng chất lượng sản phẩm, thương hiệu doanh nghiệp và góp phần nâng cao năng suất lao động quốc giaIntel là công ty đa quốc gia song nhân sự phần lớn là người Việt nên cũng gặp những vấn đề tương tự. Lãnh đạo cùng công đoàn đã thường xuyên đối thoại hàng tháng, hàng quý với người lao động để chỉ rõ tình huống thực tế rồi giải thích cho lao động hiểu, lắng nghe góp ý và phản hồi ngay ý kiến của họ. Doanh nghiệp này còn xây dựng quy trình và công cụ phản hồi ẩn danh để nhân viên đánh giá sự gương mẫu của quản lý.Để nâng cao năng suất lao động, ông Ân cho rằng cần đào tạo, chấn chỉnh tác phong con người từ khi còn đi học để dần hình thành \"thói quen, nếp nghĩ, nếp làm\". Học sinh cần được định hướng từ bậc phổ thông, đào tạo tác phong phù hợp ngành nghề đang theo học vì mỗi công việc cần ứng xử khác nhau.\"Quy chế tài chính cần cho phép công đoàn cơ sở có đủ nguồn lực trong chi tiêu cho việc đào tạo này, cũng như khen thưởng lẫn kỷ luật lao động\", ông kiến nghị.Bà Phạm Thu Lan, Viện Công nhân Công đoàn, cho rằng tiền lương, thưởng, phúc lợi ảnh hưởng trực tiếp tới năng suất, động lực làm việc, sự toàn tâm của người lao động với công việc. Họ muốn gắn bó nhưng không thể ở lại mãi với công ty khi lương thấp. Đây là lý do tỷ lệ nhảy việc tại các ngành thâm dụng lao động luôn ở mức 8-12% mỗi tháng.Theo bà Lan, nhảy việc để tìm cơ hội mới, phát huy trình độ lẫn kỹ năng là bình thường, nhưng nếu thuần túy kiếm tìm mức lương cao hơn cho công việc tương tự là sự lãng phí. Ví dụ doanh nghiệp có 1.000 công nhân nhưng mỗi tháng 100 người liên tục ra vào thì sẽ rất tốn chi phí. Tiền bạc chi cho quảng cáo tuyển dụng, phỏng vấn, làm hồ sơ, đào tạo nhân viên, trong khi khoản này có thể tiết kiệm để đầu tư cho năng suất lao động.Việc học tập nâng cao năng suất theo bà Lan là cần thiết, song \"có thực mới vực được đạo\". Lao động còn vướng bận kiếm từng bữa cơm thì không thể ưu tiên học tập, chưa kể người thu nhập thấp không có tiền đầu tư học hành cho bản thân lẫn con cái. Trong khi lao động thiếu học tập nâng cao trình độ, Việt Nam sẽ không thể nâng cấp chuỗi giá trị, mãi nằm ở khâu gia công. Muốn tăng năng suất thì động lực là nâng mặt bằng tiền lương, thu nhập của người lao động lên. Bà Lan kiến nghị Chính phủ chỉ đạo Hội đồng Tiền lương quốc gia nghiên cứu và xác lập mức lương tối thiểu thỏa đáng. Đây là sàn an sinh cơ bản để lao động chi trả sinh hoạt phí, dự phòng bất trắc và tiết kiệm cho tương lai.Lắng nghe tham luận, Thủ tướng Phạm Minh Chính đề nghị các bộ ngành, Công đoàn tiếp thu để hoàn thiện chính sách rồi tổ chức thực hiện nhằm nâng cao năng suất lao động quốc gia. Đây là một trong những thước đo quan trọng để đánh giá, so sánh trình độ phát triển giữa các nước, các lĩnh vực, địa phương trong từng quốc gia, cũng là động lực để các nước đang phát triển vươn lên thoát bẫy thu nhập trung bình.Người đứng đầu Chính phủ điểm lại năng suất lao động đã tăng 2,7 lần từ năm 2011 đến năm 2023, mỗi người làm ra 70 triệu đồng tăng lên 188,7 triệu \"là mức cao so với khu vực và đang thu hẹp dần khoảng cách với các nước\". Thu nhập lao động từ đó cũng tăng lên, đạt 7,4 triệu đồng quý I năm nay.Song Thủ tướng cũng chỉ ra nhiều hạn chế lẫn thách thức như các cán bộ công đoàn, doanh nghiệp đã nêu. Cụ thể, tỷ lệ tăng năng suất lao động giai đoạn 2021-2023 vẫn ở mức thấp so với mục tiêu đề ra. Xét về giá trị tuyệt đối, năng suất lao động của Việt Nam vẫn thấp, năm 2022 chỉ tương đương 11,4% của Singapore, 24,7% của Hàn Quốc, 26,3% của Nhật Bản, 35,4% của Malaysia, 64,8% của Thái Lan, 79% của Indonesia, 94,5% của Philippines.\"Những yếu tố nền tảng cho tăng năng suất nhanh và bền vững như hạ tầng, chuyển dịch lao động từ nông thôn sang thành thị, từ phi chính thức sang chính thức chưa có bước đột phá\", ông nói.Thủ tướng nêu rõ thời gian tới tình hình quốc tế phức tạp, khó lường tạo nên những \"cơn gió ngược\" cho sự phát triển. Bối cảnh đó đặt vấn đề nâng cao năng suất lao động là điều sống còn với đất nước. Muốn vậy cần tập trung vào \"ba đẩy mạnh, ba tiên phong, ba bứt phá\" để thúc đẩy năng suất lao động.Ba đẩy mạnh gồm hoàn thiện khung pháp lý để tạo môi trường đầu tư; huy động và sử dụng hiệu quả nguồn lực cho phát triển; đột phá chiến lược về nguồn nhân lực nhất là nhân lực chất lượng cao. Ba tiên phong chú trọng vào chuyển đổi số, các lĩnh vực mới tạo động lực cho nền kinh tế; hội nhập quốc tế để tận dụng cơ hội phát triển; thi đua tăng năng suất lao động. Ba bứt phá chọn khâu nguồn nhân lực; khoa học công nghệ và môi trường lao động.Thủ tướng yêu cầu các cấp ngành, địa phương, đặc biệt là Công đoàn Việt Nam chăm lo quyền và lợi ích chính đáng cho người lao động, đảm bảo đãi ngộ về tiền lương thưởng, các phúc lợi xã hội và triển khai nhanh chóng chương trình xây dựng một triệu căn nhà ở xã hội để người lao động có thêm chốn an cư'\n","inference(txt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":108},"id":"sS4H3_wTsDIz","executionInfo":{"status":"ok","timestamp":1716740411994,"user_tz":-420,"elapsed":1460,"user":{"displayName":"Kiệt Ngô","userId":"10546302795973663225"}},"outputId":"a6926db6-08bf-4477-90ad-622cc8b1577d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:563: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["'Thủ tướng chỉ ra nhiều hạn chế, thách thức của người lao động trong giai đoạn hiện nay như: tác phong làm việc, tác phong làm việc... đang ảnh hưởng trực tiếp tới năng suất lao động, góp phần nâng cao năng suất lao động.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":234}]},{"cell_type":"code","source":["def clean_txt(txt):\n","  ret = []\n","  ban = ['\\xe0', '\\xe1', '\\xe2', '\\xe3', '\\xe4', '\\xe5', '\\xe6', '\\xe7', '\\xe8', '\\xe9', '\\u1ecd', '\\u1ea1', '\\u1ead', '\\u1ea3', '\\u1eeb', '\\u1eed', '\\u1ec7', '\\xf4', '\\u1ebf', '\\u1ecb', '\\u1ed1']\n","  for line in txt:\n","    for x in ban:\n","      if x in line:\n","        line = line.replace(x, '')\n","        print('done')\n","    ret.append(line)\n","  return ret"],"metadata":{"id":"e484ULJec2pt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["reference = clean_txt(references)\n","prediction = clean_txt(predictions)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P7SNVknte2Rb","executionInfo":{"status":"ok","timestamp":1716739774601,"user_tz":-420,"elapsed":849,"user":{"displayName":"Kiệt Ngô","userId":"10546302795973663225"}},"outputId":"6740b4f8-de1e-46db-c0c7-ca079aaee4bf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mKết quả truyền trực tuyến bị cắt bớt đến 5000 dòng cuối.\u001b[0m\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n","done\n"]}]},{"cell_type":"code","source":["df_save = pd.DataFrame({'actuals' : references, 'predicts': predictions})"],"metadata":{"id":"UzxOp-RFUX5S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_save.to_csv('/content/result_inference.csv', encoding='ascii')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":200},"id":"_4S1yi_0XMnP","executionInfo":{"status":"error","timestamp":1716740075576,"user_tz":-420,"elapsed":383,"user":{"displayName":"Kiệt Ngô","userId":"10546302795973663225"}},"outputId":"440d24fb-d2d0-43c6-b184-eef9addbe9dd"},"execution_count":null,"outputs":[{"output_type":"error","ename":"UnicodeEncodeError","evalue":"'ascii' codec can't encode character '\\xe1' in position 4: ordinal not in range(128)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m<ipython-input-233-d628aec60409>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_save\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/result_inference.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3770\u001b[0m         )\n\u001b[1;32m   3771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3772\u001b[0;31m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[1;32m   3773\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3774\u001b[0m             \u001b[0mlineterminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlineterminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m         )\n\u001b[0;32m-> 1186\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m             )\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_need_to_save_header\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save_body\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstart_i\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_i\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0mix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslicer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_native_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_number_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m         libwriters.write_csv_rows(\n\u001b[0m\u001b[1;32m    314\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0mix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/writers.pyx\u001b[0m in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[0;34m()\u001b[0m\n","\u001b[0;31mUnicodeEncodeError\u001b[0m: 'ascii' codec can't encode character '\\xe1' in position 4: ordinal not in range(128)"]}]}]}